# app.py

import os
# Suprime logs de informa√ß√µes do TensorFlow (oneDNN etc.) e Warnings
os.environ["TF_CPP_MIN_LOG_LEVEL"] = "2"
import logging
logging.getLogger('tensorflow').setLevel(logging.ERROR)

import streamlit as st
import pandas as pd
import numpy as np
import altair as alt # Altair ainda √© importado e usado para o gr√°fico de Consumo de CPU ao Longo do Tempo
import random
import matplotlib.pyplot as plt # Matplotlib ainda √© importado mas n√£o ser√° usado para o gr√°fico principal
import plotly.express as px # Importando Plotly Express
import plotly.graph_objects as go # IMPORTANTE: Adicionado import para plotly.graph_objects

from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error
from tensorflow.keras.layers import (
    Input,
    LayerNormalization,
    MultiHeadAttention,
    Dropout,
    Dense,
    GlobalAveragePooling1D
)
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
from arch import arch_model

# Configura√ß√µes da p√°gina
st.set_page_config(
    page_title="An√°lise e Previs√£o de Consumo de CPU",
    layout="wide"
)
st.title("Dashboard de Previs√£o de Consumo de CPU")

# 1. Upload de arquivo
st.sidebar.header("1. Upload de Arquivo")
uploaded_file = st.sidebar.file_uploader(
    "Envie seu arquivo (CSV, XLS, XLSX)",
    type=["csv", "xls", "xlsx"]
)

def load_data(file) -> pd.DataFrame:
    name = file.name.lower()
    if name.endswith(".csv"):
        return pd.read_csv(file)
    else:
        return pd.read_excel(file, engine="openpyxl")

if uploaded_file is not None:
    # 2. Leitura e valida√ß√£o
    try:
        df = load_data(uploaded_file)
    except Exception as e:
        st.sidebar.error(f"Falha ao ler o arquivo: {e}")
        st.stop()

    required_cols = [
        "data",
        "consumo_cpu",
        "consumo_media_movel",
        "consumo_desvio_padrao"
    ]
    missing = [c for c in required_cols if c not in df.columns]
    if missing:
        st.sidebar.error(f"Faltando colunas: {missing}")
        st.stop()

    # 3. Convers√£o e sele√ß√£o de colunas
    df = df[required_cols].copy()
    df["data"] = pd.to_datetime(df["data"], errors="coerce")

    # 4. Filtros e ordena√ß√£o
    st.sidebar.header("2. Filtros e Ordena√ß√£o")
    
    with st.sidebar.expander("üîé Filtros e Op√ß√µes de Visualiza√ß√£o", expanded=True):
        # Filtro de Data
        min_d, max_d = df["data"].min().date(), df["data"].max().date()
        
        # --- IN√çCIO DA CORRE√á√ÉO PARA O ERRO DO INTERVALO DE DATAS ---
        selected_dates_tuple = st.date_input(
            "Intervalo de datas",
            value=(min_d, max_d),
            min_value=min_d,
            max_value=max_d,
            key="date_filter"
        )

        if len(selected_dates_tuple) == 2:
            start_date = selected_dates_tuple[0]
            end_date = selected_dates_tuple[1]
        elif len(selected_dates_tuple) == 1:
            # Se apenas uma data foi selecionada (estado intermedi√°rio),
            # use-a como data de in√≠cio e defina a data de fim como a mesma
            # para evitar o erro de desempacotamento. O usu√°rio ir√° selecionar a segunda data em seguida.
            start_date = selected_dates_tuple[0]
            end_date = selected_dates_tuple[0] 
        else:
            # Caso padr√£o, por exemplo, antes de qualquer sele√ß√£o ou se for limpo
            start_date = min_d
            end_date = max_d
        # --- FIM DA CORRE√á√ÉO ---
        
        # Filtro de Consumo de CPU
        min_cpu, max_cpu = int(df["consumo_cpu"].min()), int(df["consumo_cpu"].max()) + 1
        cpu_range = st.slider(
            "Filtro por faixa de consumo de CPU",
            min_value=min_cpu,
            max_value=max_cpu,
            value=(min_cpu, max_cpu),
            key="cpu_filter"
        )

        # Ordena√ß√£o
        sort_opts = {
            "Data ‚Üë": ("data", True),
            "Data ‚Üì": ("data", False),
            "CPU ‚Üë": ("consumo_cpu", True),
            "CPU ‚Üì": ("consumo_cpu", False),
            "M√©dia M√≥vel ‚Üë": ("consumo_media_movel", True),
            "M√©dia M√≥vel ‚Üì": ("consumo_media_movel", False)
        }
        sel = st.selectbox("Ordenar por", list(sort_opts.keys()), index=0, key="sort_box")
        
        # Sele√ß√£o de Colunas para Exibi√ß√£o
        all_cols = df.columns.tolist() + ["upper", "lower"]
        default_cols = [col for col in required_cols if col in all_cols]
        cols_to_show = st.multiselect(
            "Selecione as colunas para exibir na tabela",
            options=all_cols,
            default=default_cols,
            key="column_selector"
        )

    # Aplicando os filtros
    df_filtered = df[
        (df["data"].dt.date >= start_date) &
        (df["data"].dt.date <= end_date) &
        (df["consumo_cpu"] >= cpu_range[0]) &
        (df["consumo_cpu"] <= cpu_range[1])
    ].copy()

    # Aplicando a ordena√ß√£o
    col, asc = sort_opts[sel]
    df_filtered = df_filtered.sort_values(col, ascending=asc)


    # 5. C√°lculo de limites de desvio padr√£o
    df_filtered["upper"] = df_filtered["consumo_cpu"] + df_filtered["consumo_desvio_padrao"]
    df_filtered["lower"] = df_filtered["consumo_cpu"] - df_filtered["consumo_desvio_padrao"]

    # 6. Exibi√ß√£o da tabela
    st.success("Dados preparados com sucesso.")
    st.subheader("Amostra dos Dados Tratados")
    if not cols_to_show:
        st.warning("Selecione pelo menos uma coluna para exibir.")
    else:
        display_cols = [c for c in cols_to_show if c in df_filtered.columns]
        st.dataframe(df_filtered[display_cols].head(10), use_container_width=True)

    # 7. Gr√°fico interativo
    st.subheader("Consumo de CPU ao Longo do Tempo")
    base = alt.Chart(df_filtered).encode(x=alt.X("data:T", title="Data"))
    area = base.mark_area(color="lightblue", opacity=0.3).encode(
        y="upper:Q",
        y2="lower:Q"
    )
    cpu_line = base.mark_line(color="blue", strokeWidth=2).encode(
        y=alt.Y("consumo_cpu:Q", title="Consumo CPU")
    )
    ma_line = base.mark_line(color="orange", strokeDash=[5, 5], strokeWidth=2).encode(
        y="consumo_media_movel:Q"
    )
    st.altair_chart(alt.layer(area, cpu_line, ma_line).interactive(),
                    use_container_width=True)

    # 8. Confirma√ß√£o para iniciar previs√£o
    st.subheader("Estudo e Previs√£o de Consumo de CPU")
    run_pipeline = st.checkbox("Deseja iniciar o pipeline de previs√£o?")

    if run_pipeline:
        st.info("Pipeline de previs√£o em execu√ß√£o...")
        progress = st.progress(0)
        
        df_pipeline = df_filtered.copy()

        # 10. Normaliza√ß√£o dos dados
        progress.progress(10)
        data_to_scale = df_pipeline[[
            "consumo_cpu",
            "consumo_media_movel",
            "consumo_desvio_padrao"
        ]].values
        scaler = MinMaxScaler(feature_range=(0, 1))
        scaled_data = scaler.fit_transform(data_to_scale)

        df_norm = pd.DataFrame(
            scaled_data,
            columns=["consumo_cpu", "consumo_media_movel", "consumo_desvio_padrao"]
        )
        df_norm["data"] = df_pipeline["data"].values

        st.write("‚úÖ Normaliza√ß√£o conclu√≠da")
        st.dataframe(df_norm.head(5), use_container_width=True)

        # 11. Cria√ß√£o de sequ√™ncias
        def create_sequences_multi(data, n_steps):
            Xs, ys = [], []
            for i in range(len(data) - n_steps):
                Xs.append(data[i:(i + n_steps), :])
                ys.append(data[i + n_steps, 0])
            return np.array(Xs), np.array(ys)

        progress.progress(20)
        n_steps = 7
        X, y = create_sequences_multi(scaled_data, n_steps)
        # st.write(f"Sequ√™ncias criadas: X.shape = {X.shape}, y.shape = {y.shape}") # Removida a mensagem
        
        # 12. Divis√£o dos dados em Treino e Teste
        progress.progress(30)
        train_size = int(len(X) * 0.8)
        X_train, X_test = X[:train_size], X[train_size:]
        y_train, y_test = y[:train_size], y[train_size:]
        # st.write( # Removida a mensagem
        #     f"Dados de treino ‚Üí X_train: {X_train.shape}, y_train: {y_train.shape}\n"
        #     f"Dados de teste  ‚Üí X_test: {X_test.shape},  y_test: {y_test.shape}"
        # )

        # 13‚Äì14. Constru√ß√£o e Treinamento do Modelo Transformer
        progress.progress(45)
        st.subheader("Constru√ß√£o e Treinamento do Modelo Transformer")
        st.info("üî® Iniciando treinamento do Transformer")

        def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):
            x = LayerNormalization(epsilon=1e-6)(inputs)
            attn_output = MultiHeadAttention(
                key_dim=head_size,
                num_heads=num_heads,
                dropout=dropout
            )(x, x)
            x = Dropout(dropout)(attn_output)
            res = x + inputs

            x = LayerNormalization(epsilon=1e-6)(res)
            x = Dense(ff_dim, activation="relu")(x)
            x = Dense(inputs.shape[-1])(x)
            x = Dropout(dropout)(x)
            return x + res

        head_size = 128
        num_heads = 4
        ff_dim = 128
        num_transformer_blocks = 2
        mlp_units = [64]
        mlp_dropout = 0.4
        dropout = 0.2

        inputs = Input(shape=(n_steps, X_train.shape[2]))
        x = inputs
        for _ in range(num_transformer_blocks):
            x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)

        x = GlobalAveragePooling1D()(x)
        for dim in mlp_units:
            x = Dense(dim, activation="relu")(x)
            x = Dropout(mlp_dropout)(x)
        outputs = Dense(1)(x)

        model_transformer = Model(inputs=inputs, outputs=outputs)
        model_transformer.compile(
            loss="huber",
            optimizer=Adam(learning_rate=1e-4),
            metrics=["mae"]
        )
        model_transformer.fit(
            X_train,
            y_train,
            epochs=100,
            batch_size=32,
            validation_split=0.1,
            verbose=0
        )
        st.success("‚úÖ Modelo Transformer treinado com sucesso!")

        # 15. Treinamento do Modelo GARCH
        progress.progress(60)
        st.subheader("Treinamento do Modelo GARCH")
        st.info("üî® Ajustando GARCH nos res√≠duos")

        predictions_scaled = model_transformer.predict(X_test, verbose=0)
        predictions_desnorm = scaler.inverse_transform(
            np.concatenate([predictions_scaled,
                            np.zeros((len(predictions_scaled), 2))],
                            axis=1)
        )[:, 0]
        real_values_desnorm = scaler.inverse_transform(
            np.concatenate([y_test.reshape(-1, 1),
                            np.zeros((len(y_test), 2))],
                            axis=1)
        )[:, 0]

        residuos = real_values_desnorm - predictions_desnorm
        garch_data = pd.Series(residuos).dropna()
        am = arch_model(garch_data, vol="Garch", p=1, q=1, mean="constant")
        res_garch = am.fit(update_freq=5, disp="off")
        st.success("‚úÖ Modelo GARCH treinado com sucesso!")
        st.write(res_garch.summary())

        # --- IN√çCIO DO RESUMO DO MODELO GARCH ---
        st.markdown(rf"""
### Resumo dos Resultados do Modelo GARCH

Ap√≥s a previs√£o da tend√™ncia pelo modelo Transformer, o Modelo **GARCH (Generalized Autoregressive Conditional Heteroskedasticity)** foi aplicado aos **res√≠duos** (os erros de previs√£o) para modelar e prever a **volatilidade** desses erros. Isso √© crucial porque, em s√©ries temporais, a variabilidade dos erros (ou seja, o quanto as previs√µes podem "flutuar") muitas vezes n√£o √© constante ao longo do tempo.

**O que observar no sum√°rio do GARCH:**

* **P-values (Valores-P) dos Coeficientes:** Para entender se o modelo GARCH est√° realmente capturando a volatilidade, observe os **p-values** associados aos termos `ARCH` (Alpha) e `GARCH` (Beta) no sum√°rio.
    * Valores-p **pequenos** (geralmente menores que 0.05) para esses termos indicam que eles s√£o **estatisticamente significantes**. Isso significa que a volatilidade passada dos erros (`ARCH`) e a volatilidade passada da pr√≥pria vari√¢ncia condicional (`GARCH`) s√£o importantes para prever a volatilidade futura.
    * Um modelo GARCH com termos significantes √© um bom sinal de que a volatilidade dos res√≠duos est√° sendo modelada de forma eficaz, o que contribui para um **Intervalo de Confian√ßa** mais preciso e bem calibrado.

* **Ajuste (Fit) do Modelo:** Se o GARCH foi capaz de se ajustar bem aos res√≠duos do Transformer, significa que ele est√° capturando padr√µes na volatilidade que o Transformer, por si s√≥, n√£o conseguiria. Isso leva a um **intervalo de confian√ßa mais realista** para as suas previs√µes.

A integra√ß√£o do GARCH √© fundamental para ir al√©m de uma previs√£o pontual, fornecendo uma medida da **incerteza** e do **risco** associados √†s suas estimativas de consumo de CPU.
""")
        # --- FIM DO RESUMO DO MODELO GARCH ---

        # 16. An√°lise de Acur√°cia e M√©tricas de Erro
        progress.progress(70)
        st.subheader("An√°lise de Acur√°cia e M√©tricas de Erro")
        st.info("üîç Avaliando cobertura do intervalo de confian√ßa")

        previsao_vol = res_garch.forecast(horizon=len(X_test))
        var_forecast = previsao_vol.variance.iloc[-1]
        desvios = np.sqrt(var_forecast).values.flatten()
        limite_sup = desvios * 1.96
        limite_inf = -desvios * 1.96
        previsao_inf = predictions_desnorm + limite_inf
        previsao_sup = predictions_desnorm + limite_sup

        total = len(X_test)
        acertos = np.sum(
            (real_values_desnorm >= previsao_inf) &
            (real_values_desnorm <= previsao_sup)
        )
        acuracia_global = (acertos / total) * 100

        st.write(f"Total previs√µes: {total}")
        st.write(f"Previs√µes corretas (dentro do IC 95%): {acertos}")
        st.write(f"Acur√°cia Global do Modelo Combinado: {acuracia_global:.2f}%")

        st.markdown(f"""
**An√°lise da acur√°cia do intervalo de confian√ßa**

A acur√°cia do seu modelo n√£o se baseia em previs√£o pontual, mas num intervalo de confian√ßa de 95%.  
O valor de **{acuracia_global:.2f}%** indica que em **{acuracia_global:.2f}%** das previs√µes, o valor real caiu dentro do intervalo calculado pelo modelo.  
Para um modelo que prev√™ intervalo de 95%, uma acur√°cia pr√≥xima a 95% demonstra calibra√ß√£o correta.  
Valores acima de 90% s√£o excelentes em s√©ries temporais, e competi√ß√µes como a M4 valorizam alta cobertura de IC.
""")
        st.markdown(rf"""
### Como o Intervalo de Confian√ßa (IC) √© Calculado e Interpretado

O Intervalo de Confian√ßa √© uma ferramenta essencial para entender a **incerteza** em torno de uma previs√£o. Em vez de apenas um √∫nico valor, ele oferece uma faixa onde o valor real provavelmente estar√°.

#### **C√°lculo do IC no Modelo H√≠brido (Transformer + GARCH):**

1.  **Previs√£o de Tend√™ncia (Modelo Transformer):**
    * O modelo Transformer primeiro gera uma previs√£o do valor central (a tend√™ncia) do consumo de CPU. Esta √© a "melhor estimativa" do modelo para o futuro.
    2.  **Modelagem da Volatilidade (Modelo GARCH):**
    * Os erros (res√≠duos) da previs√£o do Transformer s√£o ent√£o passados para o modelo GARCH.
    * O GARCH √© especializado em prever a **volatilidade**, ou seja, o quanto esses erros podem variar ao longo do tempo. Ele estima o "desvio padr√£o" futuro desses erros.
    3.  **Constru√ß√£o do Intervalo:**
    * Para construir o IC de 95%, multiplicamos o desvio padr√£o da volatilidade (previsto pelo GARCH) por um fator de 1.96 (que corresponde a 95% da √°rea sob a curva de uma distribui√ß√£o normal padr√£o).
    * Esse valor √© ent√£o adicionado e subtra√≠do da previs√£o de tend√™ncia do Transformer, criando os limites superior e inferior do Intervalo de Confian√ßa.

    Portanto, o **IC de 95%** √© dado por:
    $$\text{{Previs√£o de Tend√™ncia}} \pm (1.96 \times \text{{Desvio Padr√£o da Volatilidade}})$$

#### **Interpreta√ß√£o do IC de 95%:**

* **Significado:** Um Intervalo de Confian√ßa de 95% significa que, em 95% das vezes, o valor real observado cair√° dentro da faixa que o modelo previu.
* **Confiabilidade:** Se a sua **Acur√°cia Global do Modelo Combinado** for de **{acuracia_global:.2f}%**, isso indica que em **{acuracia_global:.2f}%** das suas previs√µes no conjunto de teste, o valor real de consumo de CPU realmente esteve contido dentro do intervalo de 95% calculado pelo modelo.
* **Calibra√ß√£o:** Para um modelo com IC de 95%, o ideal √© que a acuracia global seja pr√≥xima de 95%. Um valor de **{acuracia_global:.2f}%** sugere que o seu modelo est√° **muito bem calibrado** e que seus intervalos de confian√ßa s√£o confi√°veis para capturar a incerteza inerente √† s√©rie temporal.
* **Aplica√ß√£o Pr√°tica:** Na pr√°tica, o IC permite que voc√™ n√£o apenas preveja o consumo de CPU, mas tamb√©m entenda a **margem de erro** e o **risco** associado a essa previs√£o. Isso √© crucial para tomada de decis√µes, pois permite planejar para cen√°rios de consumo m√≠nimo e m√°ximo prov√°veis.

Essa combina√ß√£o do Transformer com o GARCH √© poderosa porque lida tanto com a tend√™ncia dos dados quanto com a variabilidade dos erros de previs√£o.
""")

        # 17. C√°lculo das M√©tricas de Erro
        progress.progress(80)
        st.subheader("C√°lculo das M√©tricas de Erro")
        st.info("üìä Calculando RMSE, MAE e MAPE")

        rmse = np.sqrt(mean_squared_error(real_values_desnorm, predictions_desnorm))
        mae = mean_absolute_error(real_values_desnorm, predictions_desnorm)
        # Handle division by zero for MAPE
        mape = np.mean(
            np.abs((real_values_desnorm - predictions_desnorm) /
                   np.where(real_values_desnorm != 0, real_values_desnorm, 1e-8)) # Added check for zero
        ) * 100

        st.write(f"RMSE: {rmse:.2f}")
        st.write(f"MAE: {mae:.2f}")
        st.write(f"MAPE: {mape:.2f}%")
        
        st.markdown(rf"""
### Entendendo as M√©tricas de Erro

As m√©tricas de erro s√£o cruciais para avaliar a performance de um modelo de previs√£o. Elas quantificam o qu√£o bem as previs√µes do seu modelo se aproximam dos valores reais.

#### **RMSE (Root Mean Squared Error) - Erro Quadr√°tico M√©dio da Raiz**
* **O que representa?** O RMSE mede a raiz quadrada da m√©dia dos erros quadr√°ticos. Em termos mais simples, ele indica a magnitude m√©dia dos erros do modelo, mas penaliza mais fortemente os erros maiores. Isso o torna sens√≠vel a outliers.
* **Interpreta√ß√£o:** Quanto **menor** o valor do RMSE, melhor o modelo. O RMSE est√° na mesma unidade da vari√°vel que voc√™ est√° prevendo (neste caso, "Consumo de CPU"). Um RMSE de **{rmse:.2f}** significa que, em m√©dia, as previs√µes do seu modelo desviam dos valores reais em aproximadamente {rmse:.2f} unidades de consumo de CPU.
* **Valores bons ou ruins?** Um RMSE de {rmse:.2f} √© considerado **bom** se for pequeno em rela√ß√£o √† escala dos seus dados de consumo de CPU. Para avaliar se √© "bom", compare-o com a m√©dia ou o desvio padr√£o dos valores reais. Se o RMSE for uma pequena fra√ß√£o do desvio padr√£o do consumo de CPU, isso √© um bom sinal.
* **Refer√™ncia:** Hyndman, R. J., & Athanasopoulos, G. (2018). *Forecasting: principles and practice* (2nd ed.). OTexts.

#### **MAE (Mean Absolute Error) - Erro Absoluto M√©dio**
* **O que representa?** O MAE calcula a m√©dia das magnitudes dos erros. Ele mede a precis√£o m√©dia do modelo, dando o mesmo peso a todos os erros, grandes ou pequenos. √â menos sens√≠vel a outliers do que o RMSE.
* **Interpreta√ß√£o:** Assim como o RMSE, quanto **menor** o MAE, melhor o modelo. Ele tamb√©m est√° na mesma unidade da vari√°vel de previs√£o. Um MAE de **{mae:.2f}** indica que, em m√©dia, as previs√µes do seu modelo t√™m um erro absoluto de aproximadamente {mae:.2f} unidades de consumo de CPU.
* **Valores bons ou ruins?** Um MAE de **{mae:.2f}** pode ser considerado **bom** se for pequeno em rela√ß√£o aos valores reais de consumo. Ele fornece uma medida mais intuitiva do erro m√©dio. A mesma l√≥gica de compara√ß√£o com a escala dos dados se aplica aqui.
* **Refer√™ncia:** Shcherbakov, M. V., Brebels, A., Shcherbakova, N. L., Tyukov, A. P., Janovsky, T. A., & Kamaev, V. A. (2013). A Survey of Forecast Error Measures. *World Applied Sciences Journal*, 24(9), 1163-1175.

#### **MAPE (Mean Absolute Percentage Error) - Erro Percentual Absoluto M√©dio**
* **O que representa?** O MAPE expressa o erro como uma porcentagem do valor real. √â √∫til porque fornece uma m√©trica de erro relativa, que √© f√°cil de interpretar e comparar entre diferentes s√©ries temporais ou modelos, independentemente da escala dos dados.
* **Interpreta√ß√£o:** Quanto **menor** o MAPE, melhor o modelo. Um MAPE de **{mape:.2f}%** significa que, em m√©dia, as previs√µes do seu modelo desviam dos valores reais em {mape:.2f}%. Por exemplo, um MAPE de 10% significa que o erro m√©dio √© de 10% do valor real.
* **Valores bons ou ruins?** Um MAPE de **{mape:.2f}%** pode ser considerado **bom** ou **excelente** dependendo do dom√≠nio da aplica√ß√£o. Em muitas aplica√ß√µes de previs√£o, um MAPE abaixo de 10% √© considerado altamente preciso. Valores entre 10% e 20% s√£o geralmente bons, enquanto valores acima de 50% indicam problemas significativos. Dada a complexidade das s√©ries temporais de consumo de CPU, **{mape:.2f}%** √© um resultado muito promissor!
* **Observa√ß√£o:** O MAPE pode ser problem√°tico quando os valores reais s√£o zero ou muito pr√≥ximos de zero, pois causa divis√£o por zero ou resultados muito grandes. No seu c√≥digo, adicionamos um pequeno valor (1e-8) para mitigar esse problema, garantindo a estabilidade do c√°lculo.
* **Refer√™ncia:** Makridakis, S., & Hibon, M. (2000). The M3-Competition: results, conclusions and implications. *International Journal of Forecasting*, 16(4), 451-476.

Para uma avalia√ß√£o mais aprofundada se esses valores s√£o "bons", voc√™ precisaria compar√°-los com benchmarks da ind√∫stria ou com a performance de outros modelos no mesmo contexto de dados de consumo de CPU. No entanto, em termos gerais, quanto menores esses valores, melhor a capacidade preditiva do seu modelo.
""")


        # 18. Tabela e Gr√°ficos de Visualiza√ß√£o
        progress.progress(90)
        st.subheader("Tabela e Gr√°ficos de Visualiza√ß√£o")

        resultados = pd.DataFrame({
            "Previs√£o (Transformer)": predictions_desnorm,
            "Valor Real": real_values_desnorm,
            "Limite Inferior (95%)": previsao_inf,
            "Limite Superior (95%)": previsao_sup,
            "Acertou": (
                (previsao_inf <= real_values_desnorm) &
                (real_values_desnorm <= previsao_sup)
            )
        })

        st.write("#### Amostra dos Resultados (10 primeiras linhas)")
        st.dataframe(resultados.head(10), use_container_width=True)

        # --- SE√á√ÉO DO GR√ÅFICO CONSOLIDADO: PREVIS√ÉO VS VALOR REAL E IC 95% ---
        # Removido o gr√°fico Altair redundante e o Plotly Go duplicado.
        # Agora, o gr√°fico "Gr√°fico da Acur√°cia do Modelo" ser√° o principal e mais completo.

        # --- NOVO GR√ÅFICO: PREVIS√ïES VS. VALORES REAIS (Mantido) ---
        st.subheader("Gr√°fico: Previs√µes do Modelo Transformer vs. Valores Reais")
        st.info("üìä Comparando visualmente a previs√£o da tend√™ncia com os valores reais.")

        # Criar um DataFrame para o Plotly apenas com as colunas necess√°rias para este gr√°fico
        # Usamos .reset_index() para ter uma coluna de √≠ndice para o eixo X
        df_pred_real = resultados[['Previs√£o (Transformer)', 'Valor Real']].reset_index()
        # Usar melt para transformar o DataFrame para o formato "longo", ideal para Plotly com m√∫ltiplas linhas
        df_pred_real = df_pred_real.melt('index', var_name='Tipo de Valor', value_name='Consumo de CPU')

        fig_pred_real = px.line(df_pred_real, x='index', y='Consumo de CPU', color='Tipo de Valor',
                                title='Previs√µes vs. Valores Reais')
        
        # Ajustar o layout do gr√°fico para legendas claras
        fig_pred_real.update_layout(
            xaxis_title="Amostras de Teste",
            yaxis_title="Consumo de CPU",
            hovermode="x unified", # Permite ver os valores ao passar o mouse
            legend_title="Tipo de Valor",
            height=400, # Ajusta a altura para melhor visualiza√ß√£o
            title_font_size=20,
            xaxis_title_font_size=14,
            yaxis_title_font_size=14
        )
        st.plotly_chart(fig_pred_real, use_container_width=True)
        # --- FIM DO NOVO GR√ÅFICO ---


        # 19. Gr√°fico da Acur√°cia do Modelo (Agora o gr√°fico principal consolidado)
        progress.progress(95)
        st.subheader("Gr√°fico Principal: Previs√£o, Valor Real e Intervalo de Confian√ßa (IC 95%)")
        st.info("üìà Visualizando a previs√£o da tend√™ncia, a volatilidade e a acur√°cia do IC 95% do modelo.")

        # Preparar dados para Plotly, Plotly prefere dados "longos" para m√∫ltiplas linhas
        df_plotly = resultados.head(100).reset_index().rename(columns={"index": "Amostras de Teste"}) # Limitando a 100 pontos para melhor visualiza√ß√£o se houver muitos dados

        if len(df_plotly) > 1:
            # Criar o gr√°fico interativo com Plotly
            fig = px.line(df_plotly, x="Amostras de Teste", y="Valor Real", title="Previs√£o vs Valor Real e IC 95%")

            # Adicionar a linha de Previs√£o (Tend√™ncia)
            fig.add_scatter(x=df_plotly["Amostras de Teste"], y=df_plotly["Previs√£o (Transformer)"],
                            mode='lines', name='Previs√£o (Tend√™ncia)', line=dict(color='orange', dash='dot', width=2))

            # Adicionar o intervalo de confian√ßa como uma √°rea sombreada
            fig.add_trace(go.Scatter(
                x=df_plotly["Amostras de Teste"],
                y=df_plotly["Limite Superior (95%)"],
                mode='lines',
                name='Limite Superior (95%)',
                line=dict(width=0),
                showlegend=False
            ))
            fig.add_trace(go.Scatter(
                x=df_plotly["Amostras de Teste"],
                y=df_plotly["Limite Inferior (95%)"],
                mode='lines',
                name='Intervalo de Confian√ßa (95%)', # Nome da legenda para a √°rea
                line=dict(width=0),
                fill='tonexty',
                fillcolor='rgba(0,255,0,0.2)' # Verde transparente para a √°rea do IC
            ))

            # Adicionar os pontos de erro (fora do IC)
            erros_df = df_plotly[~df_plotly["Acertou"]]
            if not erros_df.empty:
                fig.add_trace(go.Scatter(
                    x=erros_df["Amostras de Teste"], y=erros_df["Valor Real"],
                            mode='markers', name='Erros (Fora do IC)',
                            marker=dict(symbol='x', color='red', size=10)
                ))

            # Atualizar layout para melhorar a visualiza√ß√£o e legendas
            fig.update_layout(
                height=500, # Ajusta a altura
                xaxis_title="Amostras de Teste",
                yaxis_title="Consumo de CPU",
                hovermode="x unified",
                legend_title="Legenda",
                title_font_size=20,
                xaxis_title_font_size=14,
                yaxis_title_font_size=14
            )

            st.plotly_chart(fig, use_container_width=True)

        else:
            st.warning("N√£o h√° pontos de dados suficientes no conjunto de teste (ap√≥s a filtragem) para desenhar o gr√°fico principal de previs√£o. Tente um intervalo de datas maior ou um filtro de consumo de CPU mais amplo.")


        st.markdown(f"""
**An√°lise Visual dos Resultados**

O gr√°fico acima mostra que a linha azul (Valor Real) frequentemente se mant√©m dentro da √°rea verde, que representa o **Intervalo de Confian√ßa de 95%**.

Isso confirma que o modelo acertou na maioria das previs√µes, tanto na tend√™ncia quanto na volatilidade.  
Pontos vermelhos indicam valores reais fora do IC, destacando a relev√¢ncia de quantificar incertezas.  

Com acur√°cia de **{acuracia_global:.2f}%**, seu modelo h√≠brido √© extremamente confi√°vel.
""")

        # 20. Verifica√ß√£o de Previsibilidade em Dados Desconhecidos
        progress.progress(100)
        st.subheader("Verifica√ß√£o de Previsibilidade em Dados Desconhecidos")
        st.info("üîÆ Simulando 5 pontos futuros n√£o vistos pelo modelo")
        
        # --- IN√çCIO DA ADI√á√ÉO DO CONTADOR E RESUMO ---
        correct_simulations_count = 0 
        if len(X) > 5:
            indices_aleatorios = random.sample(range(len(X) - 5, len(X)), 5)
            for i, idx in enumerate(indices_aleatorios):
                input_scaled = X[idx]
                real_scaled = y[idx]
                inp = input_scaled.reshape(1, n_steps, X.shape[2])

                # Tend√™ncia
                pred_s = model_transformer.predict(inp, verbose=0)
                pred_trend = scaler.inverse_transform(
                    np.concatenate([pred_s, np.zeros((1, 2))], axis=1)
                )[0, 0]

                # Volatilidade
                vol = res_garch.forecast(horizon=1).variance.iloc[-1].item()
                std_f = np.sqrt(vol)
                lim_sup = std_f * 1.96
                lim_inf = -std_f * 1.96

                # Verdadeiro
                real_val = scaler.inverse_transform(
                    np.concatenate([real_scaled.reshape(1, 1), np.zeros((1, 2))], axis=1)
                )[0, 0]

                # Intervalo final
                previsao_final_inferior = pred_trend + lim_inf
                previsao_final_superior = pred_trend + lim_sup

                st.write(f"**Exemplo {i+1}:**")
                st.write(f"‚Ä¢ √çndice de previs√£o: {idx}")
                st.write(f"‚Ä¢ Previs√£o Transformer: {pred_trend:.2f}")
                st.write(f"‚Ä¢ Valor real desconhecido: {real_val:.2f}")
                st.write(f"‚Ä¢ IC 95%: [{previsao_final_inferior:.2f}, {previsao_final_superior:.2f}]")

                # Avalia√ß√£o final
                if previsao_final_inferior <= real_val <= previsao_final_superior:
                    st.success(
                        "Avalia√ß√£o: O modelo acertou! O valor real est√° dentro do intervalo de confian√ßa. "
                        "A combina√ß√£o dos modelos foi eficaz para prever a volatilidade deste ponto."
                    )
                    correct_simulations_count += 1 # Incrementa o contador
                else:
                    st.error(
                        "Avalia√ß√£o: O modelo errou a previs√£o. O valor real n√£o est√° dentro do intervalo de confian√ßa. "
                        "A volatilidade foi muito alta ou at√≠pica, e os modelos n√£o conseguiram prev√™-la."
                    )
            
            st.markdown(f"---") # Linha divis√≥ria para o resumo
            st.markdown(f"**Resumo da Simula√ß√£o:** Dos 5 exemplos de dados aleat√≥rios ainda n√£o vistos pelo modelo, ele conseguiu prever **{correct_simulations_count}** corretamente (dentro do IC 95%).")
            st.markdown(f"---")
        # --- FIM DA ADI√á√ÉO DO CONTADOR E RESUMO ---

        else:
            st.warning("N√£o h√° dados suficientes para a simula√ß√£o de pontos futuros.")

else:
    st.sidebar.info("Aguardando upload de arquivo CSV ou Excel...")
